# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q6OOJgQtEQ7Yf7WQc-bgPOWA4q4cdOlc

## Análise, tratamento e pré-processamento dos dados
"""

"""Link do Kaggle: https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data"""

import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
dados = pd.read_csv('/content/drive/MyDrive/CursoML/BreastCancer/data.csv',sep=',', encoding='iso-8859-1')

dados.head()
dados.tail()

dados['diagnosis'].value_counts()

import plotly.express as px
px.histogram (dados,x = "concavity_worst", nbins=60)

dados.dtypes

dados.isnull().sum()

dados.drop(columns=['id','Unnamed: 32'],inplace=True)

dados.isnull().sum()

dados.head()

dados.to_csv('bc_tratado.csv', sep=';', encoding='utf-8', index = False)

df = pd.DataFrame.copy(dados)

df

df['diagnosis'].replace({'B':0, 'M': 1}, inplace=True)

df

df['diagnosis'].value_counts()

previsores = df.iloc[:, 1:32].values

alvo = df.iloc[:, 0].values

alvo

"""Escalonando:


"""

from sklearn.preprocessing import StandardScaler

previsores_esc = StandardScaler().fit_transform(previsores)

previsores_esc

previsoresdf = pd.DataFrame(previsores_esc)

"""Teste da redução de dimensionalidade:"""

from sklearn.decomposition import PCA

pca = PCA(n_components=3)

previsores_pca = pca.fit_transform(previsores)

previsores_pca.shape

pca.explained_variance_ratio_

"""Treino e teste:"""

from sklearn.model_selection import train_test_split

x_treino, x_teste, y_treino, y_teste = train_test_split(previsores_esc, alvo, test_size = 0.3, random_state = 0)

"""## Naive Bayes"""

from sklearn.naive_bayes import GaussianNB

naive = GaussianNB()

naive.fit(x_treino, y_treino)

previsoes_naive = naive.predict(x_teste)

previsoes_naive

y_teste

print("Acurácia do teste: %.2f%%" % (accuracy_score(y_teste, previsoes_naive) * 100.0))

confusion_matrix(y_teste, previsoes_naive)

kfold = KFold(n_splits = 30, shuffle=True, random_state = 5)

modelo = GaussianNB()
resultado = cross_val_score(modelo, previsores, alvo, cv = kfold)

print("Acurácia Média: %.2f%%" % (resultado.mean() * 100.0))

"""Acurácia média do previsores: 93.82%

Acurácia média do previsores_esc: 93.47%

## Máquina de Suporte de Vetores (SVM)
"""

from sklearn.svm import SVC

svm = SVC(kernel='rbf', random_state=1, C = 2)

svm.fit(x_treino, y_treino)

previsoes_svm = svm.predict(x_teste)

previsoes_svm

y_teste

print("Acurácia do teste: %.2f%%" % (accuracy_score(y_teste, previsoes_svm) * 100.0))

confusion_matrix(y_teste, previsoes_svm)

print(classification_report(y_teste, previsoes_svm))

previsoes_treino = svm.predict(x_treino)

previsoes_treino

accuracy_score(y_treino, previsoes_treino)

confusion_matrix(y_treino, previsoes_treino)

modelo = SVC(kernel='rbf', random_state=1, C = 2)
resultado = cross_val_score(modelo, previsores_esc, alvo, cv = kfold)

print("Acurácia Média: %.2f%%" % (resultado.mean() * 100.0))

"""Acurácia média do previsores: 91.72%

Acurácia média do previsores_esc: 97.88%

## Regressão Logística
"""

from sklearn.linear_model import LogisticRegression

logistica = LogisticRegression(random_state=1, max_iter=500, penalty="l2",tol=0.0001, C=1,solver="lbfgs")

logistica.fit(x_treino, y_treino)

previsoes_logistica = logistica.predict(x_teste)
previsoes_logistica

y_teste

print("Acurácia do teste: %.2f%%" % (accuracy_score(y_teste, previsoes_logistica) * 100.0))

confusion_matrix(y_teste, previsoes_logistica)

print(classification_report(y_teste, previsoes_logistica))

previsoes_treino = logistica.predict(x_treino)
previsoes_treino

accuracy_score(y_treino, previsoes_treino)

confusion_matrix(y_treino, previsoes_treino)

modelo = LogisticRegression(random_state=1, max_iter=600, penalty="l2",tol=0.0001, C=1,solver="lbfgs")

resultado = cross_val_score(modelo, previsores_esc, alvo, cv = kfold)

print("Acurácia Média: %.2f%%" % (resultado.mean() * 100.0))

"""Acurácia média do previsores: 94.71%

Acurácia média do previsores_esc: 98.06%

## Aprendizagem Baseada em Instâncias (KNN)
"""

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=7, metric='minkowski', p=1)
knn.fit(x_treino, y_treino)

previsoes_knn = knn.predict(x_teste)
previsoes_knn

y_teste

print("Acurácia do teste: %.2f%%" % (accuracy_score(y_teste, previsoes_knn) * 100.0))

confusion_matrix(y_teste, previsoes_knn)

print(classification_report(y_teste, previsoes_knn))

previsoes_knn = knn.predict(x_treino)
previsoes_knn

accuracy_score(y_treino, previsoes_knn)

confusion_matrix(y_treino, previsoes_knn)

modelo = KNeighborsClassifier(n_neighbors=7, metric='minkowski', p = 1)

resultado = cross_val_score(modelo, previsores, alvo, cv = kfold)

print("Acurácia Média: %.2f%%" % (resultado.mean() * 100.0))

"""Acurácia Média do previsores: 93.13%

Acurácia Média do previsores_esc: 96.65%

## Árvore de Decisão
"""

from sklearn.tree import DecisionTreeClassifier

arvore = DecisionTreeClassifier(criterion='entropy', random_state = 0, max_depth=3)

arvore.fit(x_treino, y_treino)

previsoes_arvore = arvore.predict(x_teste)

previsoes_arvore

y_teste

print("Acurácia do teste: %.2f%%" % (accuracy_score(y_teste, previsoes_arvore) * 100.0))

confusion_matrix(y_teste, previsoes_arvore)

print(classification_report(y_teste, previsoes_arvore))

previsoes_treino = arvore.predict(x_treino)

print("Acurácia do treino: %.2f%%" % (accuracy_score(y_treino, previsoes_treino) * 100.0))

confusion_matrix(y_treino, previsoes_treino)

modelo = DecisionTreeClassifier(criterion='entropy', random_state = 0, max_depth=3)

resultado = cross_val_score(modelo, previsores_esc, alvo, cv = kfold)

print("Acurácia Média: %.2f%%" % (resultado.mean() * 100.0))

"""Acurácia Média do previsores: 93.67%

Acurácia Média do previsores_esc: 93.67% (Mesmo resultado)

## Random Forest
"""

from sklearn.ensemble import RandomForestClassifier

random = RandomForestClassifier(n_estimators=150, criterion='entropy', random_state = 0, max_depth=4)
random.fit(x_treino, y_treino)

previsoes_random = random.predict(x_teste)
previsoes_random

y_teste

print("Acurácia do teste: %.2f%%" % (accuracy_score(y_teste, previsoes_random) * 100.0))

confusion_matrix(y_teste, previsoes_random)

print(classification_report(y_teste, previsoes_random))

previsores_treino = random.predict(x_treino)

print("Acurácia do treino: %.2f%%" % (accuracy_score(y_treino, previsoes_treino) * 100.0))

confusion_matrix(y_treino, previsoes_treino)

modelo = RandomForestClassifier(n_estimators=150, criterion='entropy', random_state = 0, max_depth=4)

resultado = cross_val_score(modelo, previsores_esc, alvo, cv = kfold)

print("Acurácia Média: %.2f%%" % (resultado.mean() * 100.0))

"""Acurácia Média de previsores: 95.76%

Acurácia Média de previsores_esc: 95.76%

## XGBoost
"""

from xgboost import XGBClassifier

xg = XGBClassifier(max_depth=2, learning_rate=0.05, n_estimators=250, objective='binary:logistic', random_state=3)

xg.fit(x_treino,y_treino)

previsoes_xg = xg.predict(x_teste)

previsoes_xg

print("Acurácia do teste: %.2f%%" % (accuracy_score(y_teste, previsoes_xg) * 100.0))

confusion_matrix(y_teste, previsoes_xg)

print(classification_report(y_teste, previsoes_xg))

previsoes_treino = xg.predict(x_treino)
previsoes_treino

y_treino

print("Acurácia do treino: %.2f%%" % (accuracy_score(y_treino, previsoes_treino) * 100.0))

modelo = XGBClassifier(max_depth=2, learning_rate=0.05, n_estimators=250, objective='binary:logistic', random_state=3)

resultado = cross_val_score(modelo, previsores_esc, alvo, cv = kfold)

print("Acurácia Média: %.2f%%" % (resultado.mean() * 100.0))

"""Acurácia Média do previsores: 96.65%

Acurácia Média do previsores_esc: 96.65%

## LightBGM
"""

!pip install lightgbm

import lightgbm as lgb

dataset = lgb.Dataset(x_treino,label=y_treino)

parametros = {'num_leaves':30,'objective':'binary','max_depth':3,'learning_rate':.1,'max_bin':50}

lgbm=lgb.train(parametros,dataset,num_boost_round=200)

previsoes_lgbm = lgbm.predict(x_teste)
previsoes_lgbm

for i in range(0, 171):
    if previsoes_lgbm[i] >= .5:
       previsoes_lgbm[i] = 1
    else:
       previsoes_lgbm[i] = 0

previsoes_lgbm

y_teste

print("Acurácia: %.2f%%" % (accuracy_score(y_teste, previsoes_lgbm) * 100.0))

confusion_matrix(y_teste, previsoes_lgbm)

previsoes_treino = lgbm.predict(x_treino)
previsoes_treino

for i in range(0, 398):
    if previsoes_treino[i] >= .5:
       previsoes_treino[i] = 1
    else:
       previsoes_treino[i] = 0

previsoes_treino

print("Acurácia do treino: %.2f%%" % (accuracy_score(y_treino, previsoes_treino) * 100.0))

confusion_matrix(y_treino, previsoes_treino)

modelo = lgb.LGBMClassifier(num_leaves = 100, objective = 'binary',max_depth = 3, learning_rate = .1, max_bin =50)

resultado = cross_val_score(modelo, previsores_esc, alvo, cv = kfold)

print("Acurácia Média: %.2f%%" % (resultado.mean() * 100.0))

"""Acurácia Média do previsores: 96.11%

Acurácia Média do previsores_esc: 97.52%

## Catboost
"""

!pip install catboost

from catboost import CatBoostClassifier

df

previsores2 = df.iloc[:, 1:32]

alvo2 = df.iloc[:, 0]

x_treino, x_teste, y_treino, y_teste = train_test_split(previsores2, alvo2, test_size = 0.3, random_state = 0)

catboost = CatBoostClassifier(task_type='CPU', iterations=100, learning_rate=0.1, depth = 8, random_state = 5,eval_metric="Accuracy")

catboost.fit( x_treino, y_treino, plot=True, eval_set=(x_teste, y_teste))

previsoes_cat = catboost.predict(x_teste)
previsoes_cat

y_teste

print("Acurácia do teste: %.2f%%" % (accuracy_score(y_teste, previsoes_cat) * 100.0))

confusion_matrix(y_teste, previsoes_cat)

previsoes_treino = catboost.predict(x_treino)
previsoes_treino

accuracy_score(y_treino, previsoes_treino)

confusion_matrix(y_treino, previsoes_treino)

modelo = CatBoostClassifier(task_type='CPU', iterations=100, learning_rate=0.1, depth = 8, random_state = 5,eval_metric="Accuracy")

resultado = cross_val_score(modelo, previsores_esc, alvo, cv = kfold)

print("Acurácia Média: %.2f%%" % (resultado.mean() * 100.0))

"""## Resultados

Naive Bayes: 93.82% (Sem escalonamento)

SVM: 97.88% (Escalonado)

Regressão Logística: 98.06% (Escalonado)

KNN: 96.65% (Escalonado)

Árvore de decisão: 93.67%

Random Forest: 95.76%

XGBoost: 96.65%

LightGBM: 97.52% (Escalonado)

Catboost: 97.16%
"""
